{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_phase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGDMcyExp6UrNkrenNXQYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravanisasu/AOS_19MCMB14/blob/master/first_phase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-MWsoiWOC8J",
        "outputId": "7313647b-5611-4aa8-9b29-8f0f83300362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Importing the required packages\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "import os\n",
        "import re\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras import optimizers\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7M9JpeG0CYa"
      },
      "source": [
        "#Define file paths required for the model\n",
        "\n",
        "# embedding bin file\n",
        "embed_file = \"/content/sim.expand.200d.vec\"\n",
        "\n",
        "#Define Hyper parameters\n",
        "max_inp_len = 20000\n",
        "# the dimension of vectors to be used\n",
        "embed_dim = 200\n",
        "rounding = 6\n",
        "# filter sizes of the different conv layers \n",
        "filter_sizes = [3,4,5]\n",
        "num_filters = 1\n",
        "pool_size = 199\n",
        "# dropout probability\n",
        "drop = 0.5\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "epochs = 30"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DbBN4tosBE9",
        "outputId": "18e1d11f-3eb5-4e92-d240-aa7bfe77349a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#define embedding dictionary and embed matrix for the vocabulary\n",
        "embeddings_dic = dict()\n",
        "f = open(embed_file,encoding='utf8')\n",
        "with open(embed_file, 'r', encoding='utf-8') as e_file:\n",
        "  for line in e_file:\n",
        "    splitlines = line.split()\n",
        "    word = splitlines[0].strip()\n",
        "    coefs = np.asarray(splitlines[1:], dtype='float32')\n",
        "    embeddings_dic[word] = coefs\n",
        "\n",
        "print(\"length of embedding dictionary\",len(embeddings_dic))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of embedding dictionary 70428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqa1tA-lt6e8",
        "outputId": "59a5558a-a9eb-413b-bb4b-44bc16ca65d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vocabulary_size = len(embeddings_dic.keys())\n",
        "embed_token = Tokenizer()\n",
        "embed_token.fit_on_texts(embeddings_dic.keys())\n",
        "embedding_matrix = np.zeros((vocabulary_size, embed_dim))\n",
        "for word, index in embed_token.word_index.items():\n",
        "  embedding_matrix[index] = embeddings_dic.get(word)\n",
        "print(\"embedding_matrix dimension\",len(embedding_matrix),len(embedding_matrix[0]))\n",
        "print(\"no of token in the tokenizer\",len(embed_token.word_index) + 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding_matrix dimension 70428 200\n",
            "no of token in the tokenizer 70428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laF6m-NotXFw"
      },
      "source": [
        "#function to pre process the document\n",
        "def process_doc(path_file,embed_token) :\n",
        "\n",
        "  #tokenizing the words \n",
        "  with open(path_file,'r', encoding='utf-8') as tok_file :\n",
        "    file_words = list(tok_file)[0].split()\n",
        "    \n",
        "  #removing the stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_words = []  \n",
        "  for word in file_words: \n",
        "      if word not in stop_words and word.isalpha(): \n",
        "          filtered_words.append(word)\n",
        "\n",
        "  # applying stemming using PorterStemmer\n",
        "\n",
        "  p_stemmer = PorterStemmer()\n",
        "  stem_words=[]\n",
        "  for word in filtered_words:\n",
        "    stem_words.append(p_stemmer.stem(word))\n",
        "    \n",
        "  #tokenizing the words using the embed token\n",
        "  tokens=[]\n",
        "  for word in stem_words:\n",
        "    try:\n",
        "      tokens.append(embed_token.word_index[word])\n",
        "    except:\n",
        "      tokens.append(1)\n",
        "\n",
        "  tokens.extend([0]*(max_inp_len-len(tokens)))\n",
        "\n",
        "  return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q4J5yKMfxDP"
      },
      "source": [
        "#input dataset\n",
        "def input_data(meta_file):\n",
        "  documents = list()\n",
        "  with open(meta_file,'r', encoding='utf-8') as m_file :\n",
        "    year = meta_file.split('/')[2].split('.')[0]\n",
        "    dir_path = os.path.dirname(meta_file) + '/' +year\n",
        "    for line in m_file.readlines():\n",
        "      inp_path_file = dir_path +'/'+ line.split()[0] + '.mda'\n",
        "      # get tokens for the doc\n",
        "      tokens = process_doc(inp_path_file,embed_token)\n",
        "      documents.append(tokens)\n",
        "  return documents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVi-HHNCPHkz",
        "outputId": "a9f8debd-352b-4324-b4e6-9733914452af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "input_X = input_data('/content/1996.meta.txt')\n",
        "print(len(input_X))\n",
        "input_X.extend(input_data('/content/1997.meta.txt'))\n",
        "print(len(input_X))\n",
        "input_X.extend(input_data('/content/1998.meta.txt'))\n",
        "print(len(input_X))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1203\n",
            "2908\n",
            "4848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCdDHfYt3l7"
      },
      "source": [
        "#output dataset\n",
        "def output_data(out_path_file):\n",
        "  output=[]\n",
        "  with open(out_path_file,'r', encoding='utf-8') as out_file :\n",
        "    for line in out_file.readlines():\n",
        "      output.append(float(line.split()[0]))\n",
        "  return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp_iyrbHQXR6",
        "outputId": "61c8d6eb-9f33-4688-d702-f7aa18b84c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "output_Y = output_data('/content/1996.logvol.+12.txt')\n",
        "print(len(output_Y))\n",
        "output_Y.extend(output_data('/content/1997.logvol.+12.txt'))\n",
        "print(len(output_Y))\n",
        "output_Y.extend(output_data('/content/1998.logvol.+12.txt'))\n",
        "print(len(output_Y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1203\n",
            "2908\n",
            "4848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lar37ukkqj-i",
        "outputId": "6bee019f-3ff6-4d8c-b72e-67b31183fe42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.array(input_X).shape)\n",
        "#np.array(output_Y).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4848, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIOmvEheA_Mw"
      },
      "source": [
        "def define_model(max_inp_len,vocabulary_size,embed_dim,filter_sizes,num_filters,pool_size,drop,learning_rate):\n",
        "  \n",
        "  # input and embedding matrix\n",
        "  inputs = Input(shape=(max_inp_len,))\n",
        "  embedding = Embedding(vocabulary_size, embed_dim, weights=[embedding_matrix],trainable = False)(inputs)\n",
        "\n",
        "  custom_objects={'leaky_relu': tf.nn.leaky_relu}\n",
        "\n",
        "  # channel 1 convolution and local max-pooling\n",
        "  convolution_1 = Conv1D(filters=num_filters, kernel_size=filter_sizes[0], activation=custom_objects['leaky_relu'])(embedding)\n",
        "  pool_1 = MaxPooling1D(pool_size=pool_size)(convolution_1)\n",
        "  \n",
        "\t# channel 2 convolution and local max-pooling\n",
        "  convolution_4 = Conv1D(filters=num_filters, kernel_size=filter_sizes[1], activation=custom_objects['leaky_relu'])(embedding)\n",
        "  pool_2 = MaxPooling1D(pool_size=pool_size)(convolution_4)\n",
        "  \n",
        "  # channel 3 convolution and local max-pooling\n",
        "  convolution_5 = Conv1D(filters=num_filters, kernel_size=filter_sizes[2], activation=custom_objects['leaky_relu'])(embedding)\n",
        "  pool_3 = MaxPooling1D(pool_size=pool_size)(convolution_5)\n",
        "  \n",
        "  # merge and dropout\n",
        "  merged = concatenate([pool_1,pool_2,pool_3],axis=1)\n",
        "  drop_out = Dropout(drop)(merged)\n",
        "  flat = Flatten()(drop_out)\n",
        "\n",
        "  # 2 fully connected layers\n",
        "  dense1 = Dense(100, activation=custom_objects['leaky_relu'])(flat)\n",
        "  outputs = Dense(1, activation=custom_objects['leaky_relu'])(dense1)\n",
        "  model = Model(inputs=[inputs], outputs=outputs)\n",
        "    \n",
        "  opt = optimizers.SGD(learning_rate=learning_rate)\n",
        "  model.compile(loss='mse', optimizer=opt, metrics=[RootMeanSquaredError()])\n",
        "\n",
        "\t# summarize\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeyM-2XMBi7O",
        "outputId": "9e4f0c53-51ab-495d-f7ec-99ff6306b9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_X = np.array(input_X)\n",
        "output_Y = np.array(output_Y)\n",
        "#output_Y = tf.keras.utils.normalize(output_Y)\n",
        "print(input_X.shape)\n",
        "print(output_Y.shape)\n",
        "from sklearn import model_selection as ms\n",
        "\n",
        "x_train, x_test, y_train, y_test = ms.train_test_split(input_X, output_Y, random_state = 1 ,test_size=0.33)\n",
        "\n",
        "print(\"total input shape\",input_X.shape)\n",
        "print(\"total output shape\",output_Y.shape)\n",
        "print(\"training input shape\",x_train.shape)\n",
        "print(\"training output shape\",y_train.shape)\n",
        "print(\"testing input shape\",x_test.shape)\n",
        "print(\"testing output shape\",y_test.shape)\n",
        "\n",
        "# define model\n",
        "model = define_model(max_inp_len,vocabulary_size,embed_dim,filter_sizes,num_filters,pool_size,drop,learning_rate)\n",
        "# fit mode\n",
        "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs)\n",
        "model.save('model.h5')\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4848, 20000)\n",
            "(4848,)\n",
            "total input shape (4848, 20000)\n",
            "total output shape (4848,)\n",
            "training input shape (3248, 20000)\n",
            "training output shape (3248,)\n",
            "testing input shape (1600, 20000)\n",
            "testing output shape (1600,)\n",
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(None, 20000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 20000, 200)   14085600    input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 19998, 1)     601         embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 19997, 1)     801         embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 19996, 1)     1001        embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling1D) (None, 100, 1)       0           conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling1D) (None, 100, 1)       0           conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling1D) (None, 100, 1)       0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 300, 1)       0           max_pooling1d_13[0][0]           \n",
            "                                                                 max_pooling1d_14[0][0]           \n",
            "                                                                 max_pooling1d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 300, 1)       0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 300)          0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 100)          30100       flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            101         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,118,204\n",
            "Trainable params: 32,604\n",
            "Non-trainable params: 14,085,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 11.0739 - root_mean_squared_error: 3.3278\n",
            "Epoch 2/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 10.2041 - root_mean_squared_error: 3.1944\n",
            "Epoch 3/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 7.5015 - root_mean_squared_error: 2.7389\n",
            "Epoch 4/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 1.8491 - root_mean_squared_error: 1.3598\n",
            "Epoch 5/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4370 - root_mean_squared_error: 0.6611\n",
            "Epoch 6/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4151 - root_mean_squared_error: 0.6443\n",
            "Epoch 7/30\n",
            "65/65 [==============================] - 29s 439ms/step - loss: 0.4037 - root_mean_squared_error: 0.6354\n",
            "Epoch 8/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4131 - root_mean_squared_error: 0.6428\n",
            "Epoch 9/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.4100 - root_mean_squared_error: 0.6403\n",
            "Epoch 10/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4140 - root_mean_squared_error: 0.6434\n",
            "Epoch 11/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4102 - root_mean_squared_error: 0.6404\n",
            "Epoch 12/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4035 - root_mean_squared_error: 0.6352\n",
            "Epoch 13/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.4055 - root_mean_squared_error: 0.6368\n",
            "Epoch 14/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.3993 - root_mean_squared_error: 0.6319\n",
            "Epoch 15/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3983 - root_mean_squared_error: 0.6311\n",
            "Epoch 16/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.4056 - root_mean_squared_error: 0.6369\n",
            "Epoch 17/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.3980 - root_mean_squared_error: 0.6309\n",
            "Epoch 18/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4043 - root_mean_squared_error: 0.6358\n",
            "Epoch 19/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3988 - root_mean_squared_error: 0.6315\n",
            "Epoch 20/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4012 - root_mean_squared_error: 0.6334\n",
            "Epoch 21/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4045 - root_mean_squared_error: 0.6360\n",
            "Epoch 22/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3922 - root_mean_squared_error: 0.6262\n",
            "Epoch 23/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3957 - root_mean_squared_error: 0.6291\n",
            "Epoch 24/30\n",
            "65/65 [==============================] - 29s 440ms/step - loss: 0.4042 - root_mean_squared_error: 0.6357\n",
            "Epoch 25/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3945 - root_mean_squared_error: 0.6281\n",
            "Epoch 26/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3921 - root_mean_squared_error: 0.6262\n",
            "Epoch 27/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3914 - root_mean_squared_error: 0.6256\n",
            "Epoch 28/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3913 - root_mean_squared_error: 0.6256\n",
            "Epoch 29/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3906 - root_mean_squared_error: 0.6249\n",
            "Epoch 30/30\n",
            "65/65 [==============================] - 29s 441ms/step - loss: 0.3956 - root_mean_squared_error: 0.6290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjyXD9-Y9A33",
        "outputId": "48d5a45d-8732-40b9-c7bb-ed8d7900a118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss_T, RMSE_T = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train Error: %f' % (RMSE_T))\n",
        " \n",
        "# evaluate model on test dataset dataset\n",
        "loss_V, RMSE_V = model.evaluate(x_test,y_test, verbose=0)\n",
        "print('Test Error: %f' % (RMSE_V))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Error: 0.559181\n",
            "Test Error: 0.563773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daLyVCcEzjmJ",
        "outputId": "063919eb-4869-4ea0-81d1-1627df962d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "fig, ax1 = plt.subplots()\n",
        "epochs_arr =[i for i in range(0,epochs)]\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('RMSE', color=color)\n",
        "ax1.plot(epochs_arr, history.history['root_mean_squared_error'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "plt.show()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'root_mean_squared_error'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}