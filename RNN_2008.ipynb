{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_phase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOQmtCOJs0mCTWfzNHhqeh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravanisasu/volatality_pred/blob/master/RNN_2008.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-MWsoiWOC8J",
        "outputId": "374e2606-783d-42ba-9ba4-3d3805558dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Importing the required packages\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "import os\n",
        "import re\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras import optimizers\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7M9JpeG0CYa"
      },
      "source": [
        "#Define file paths required for the model\n",
        "\n",
        "# embedding bin file\n",
        "embed_file = \"/content/sim.expand.200d.vec\"\n",
        "\n",
        "#Define Hyper parameters\n",
        "max_inp_len = 20000\n",
        "# the dimension of vectors to be used\n",
        "embed_dim = 200\n",
        "rounding = 6\n",
        "# filter sizes of the different conv layers \n",
        "filter_sizes = [3,4,5]\n",
        "num_filters = 1\n",
        "pool_size = 199\n",
        "# dropout probability\n",
        "drop = 0.5\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "epochs = 50"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DbBN4tosBE9",
        "outputId": "fbbbdf84-1adc-450f-a398-202f96c1a9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#define embedding dictionary and embed matrix for the vocabulary\n",
        "embeddings_dic = dict()\n",
        "f = open(embed_file,encoding='utf8')\n",
        "with open(embed_file, 'r', encoding='utf-8') as e_file:\n",
        "  for line in e_file:\n",
        "    splitlines = line.split()\n",
        "    word = splitlines[0].strip()\n",
        "    coefs = np.asarray(splitlines[1:], dtype='float32')\n",
        "    embeddings_dic[word] = coefs\n",
        "\n",
        "print(\"length of embedding dictionary\",len(embeddings_dic))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of embedding dictionary 70428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqa1tA-lt6e8",
        "outputId": "138fa6cb-c440-4bd6-a753-94b908f3e773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vocabulary_size = len(embeddings_dic.keys())\n",
        "embed_token = Tokenizer()\n",
        "embed_token.fit_on_texts(embeddings_dic.keys())\n",
        "embedding_matrix = np.zeros((vocabulary_size, embed_dim))\n",
        "for word, index in embed_token.word_index.items():\n",
        "  embedding_matrix[index] = embeddings_dic.get(word)\n",
        "print(\"embedding_matrix dimension\",len(embedding_matrix),len(embedding_matrix[0]))\n",
        "print(\"no of token in the tokenizer\",len(embed_token.word_index) + 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding_matrix dimension 70428 200\n",
            "no of token in the tokenizer 70428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laF6m-NotXFw"
      },
      "source": [
        "#function to pre process the document\n",
        "def process_doc(path_file,embed_token) :\n",
        "\n",
        "  #tokenizing the words \n",
        "  with open(path_file,'r', encoding='utf-8') as tok_file :\n",
        "    file_words = list(tok_file)[0].split()\n",
        "    \n",
        "  #removing the stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_words = list()  \n",
        "  for word in file_words: \n",
        "      if word not in stop_words and word.isalpha(): \n",
        "          filtered_words.append(word)\n",
        "\n",
        "  # applying stemming using PorterStemmer\n",
        "\n",
        "  p_stemmer = PorterStemmer()\n",
        "  stem_words=list()\n",
        "  for word in filtered_words:\n",
        "    stem_words.append(p_stemmer.stem(word))\n",
        "    \n",
        "  #tokenizing the words using the embed token\n",
        "  tokens=list()\n",
        "  for word in stem_words:\n",
        "    try:\n",
        "      tokens.append(embed_token.word_index[word])\n",
        "    except:\n",
        "      tokens.append(1)\n",
        "  if max_inp_len > len(tokens) :\n",
        "    tokens.extend([0]*(max_inp_len-len(tokens)))\n",
        "  elif max_inp_len < len(tokens) :\n",
        "    tokens=tokens[:max_inp_len]\n",
        "  else:\n",
        "    pass\n",
        "  return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q4J5yKMfxDP"
      },
      "source": [
        "#input dataset\n",
        "def input_data(meta_file):\n",
        "  documents = list()\n",
        "  with open(meta_file,'r', encoding='utf-8') as m_file :\n",
        "    year = meta_file.split('/')[2].split('.')[0]\n",
        "    dir_path = os.path.dirname(meta_file) + '/' +year\n",
        "    for line in m_file.readlines():\n",
        "      inp_path_file = dir_path +'/'+ line.split()[0] + '.mda'\n",
        "      # get tokens for the doc\n",
        "      tokens = process_doc(inp_path_file,embed_token)\n",
        "      documents.append(tokens)\n",
        "  return documents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVi-HHNCPHkz",
        "outputId": "20c85973-ae81-4a87-f26d-f7d12c19b3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_X = list()\n",
        "input_X.extend(input_data('/content/2008.meta.txt'))\n",
        "print(len(input_X))\n",
        "#input_X.extend(input_data('/content/1997.meta.txt'))\n",
        "#print(len(input_X))\n",
        "#input_X.extend(input_data('/content/1998.meta.txt'))\n",
        "#print(len(input_X))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCdDHfYt3l7"
      },
      "source": [
        "#output dataset\n",
        "def output_data(out_path_file):\n",
        "  output=[]\n",
        "  with open(out_path_file,'r', encoding='utf-8') as out_file :\n",
        "    for line in out_file.readlines():\n",
        "      output.append(float(line.split()[0]))\n",
        "  return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp_iyrbHQXR6",
        "outputId": "830ca41f-f03c-43ae-9fa5-20e75f81be52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_Y = output_data('/content/2008.logvol.+12.txt')\n",
        "print(len(output_Y))\n",
        "#output_Y.extend(output_data('/content/1997.logvol.+12.txt'))\n",
        "#print(len(output_Y))\n",
        "#output_Y.extend(output_data('/content/1998.logvol.+12.txt'))\n",
        "#print(len(output_Y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lar37ukkqj-i",
        "outputId": "25fb5540-cbd8-439f-bdb3-e1e7306b14fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.array(input_X).shape)\n",
        "#np.array(output_Y).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2509, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIOmvEheA_Mw"
      },
      "source": [
        "def define_model(max_inp_len,vocabulary_size,embed_dim,filter_sizes,num_filters,pool_size,drop,learning_rate):\n",
        "  \n",
        "  # input and embedding matrix\n",
        "  inputs = Input(shape=(max_inp_len,))\n",
        "  embedding = Embedding(vocabulary_size, embed_dim, weights=[embedding_matrix],trainable = False)(inputs)\n",
        "\n",
        "  custom_objects={'leaky_relu': tf.nn.leaky_relu}\n",
        "  \n",
        "  # Layer1 RNN with LSTM\n",
        "  layer_1 = LSTM(units=100, activation = 'tanh' )(embedding)\n",
        "       \n",
        "  # 1 fully connected layers\n",
        "  outputs = Dense(1, activation=custom_objects['leaky_relu'])(layer_1)\n",
        "  model = Model(inputs=[inputs], outputs=outputs)\n",
        "    \n",
        "  opt = optimizers.SGD(learning_rate=learning_rate)\n",
        "  model.compile(loss='mse', optimizer=opt, metrics=[RootMeanSquaredError()])\n",
        "\n",
        "\t# summarize\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeyM-2XMBi7O",
        "outputId": "a9865366-b1b3-478b-8edf-2ee4e063f2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_X = np.array(input_X)\n",
        "output_Y = np.array(output_Y)\n",
        "#output_Y = tf.keras.utils.normalize(output_Y)\n",
        "print(input_X.shape)\n",
        "print(output_Y.shape)\n",
        "from sklearn import model_selection as ms\n",
        "\n",
        "x_train, x_test, y_train, y_test = ms.train_test_split(input_X, output_Y, random_state = 1 ,test_size=0.33)\n",
        "\n",
        "print(\"total input shape\",input_X.shape)\n",
        "print(\"total output shape\",output_Y.shape)\n",
        "print(\"training input shape\",x_train.shape)\n",
        "print(\"training output shape\",y_train.shape)\n",
        "print(\"testing input shape\",x_test.shape)\n",
        "print(\"testing output shape\",y_test.shape)\n",
        "\n",
        "# define model\n",
        "model = define_model(max_inp_len,vocabulary_size,embed_dim,filter_sizes,num_filters,pool_size,drop,learning_rate)\n",
        "# fit mode\n",
        "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs)\n",
        "model.save('model.h5')\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2509, 20000)\n",
            "(2509,)\n",
            "total input shape (2509, 20000)\n",
            "total output shape (2509,)\n",
            "training input shape (1681, 20000)\n",
            "training output shape (1681,)\n",
            "testing input shape (828, 20000)\n",
            "testing output shape (828,)\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 20000)]           0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 20000, 200)        14085600  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 14,206,101\n",
            "Trainable params: 120,501\n",
            "Non-trainable params: 14,085,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 8.9284 - root_mean_squared_error: 2.9880\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 8.7729 - root_mean_squared_error: 2.9619\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 8.6172 - root_mean_squared_error: 2.9355\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 8.4555 - root_mean_squared_error: 2.9078\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 45s 1s/step - loss: 8.2829 - root_mean_squared_error: 2.8780\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 8.0931 - root_mean_squared_error: 2.8448\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 7.8760 - root_mean_squared_error: 2.8064\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 7.6154 - root_mean_squared_error: 2.7596\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 7.2836 - root_mean_squared_error: 2.6988\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 6.8346 - root_mean_squared_error: 2.6143\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 6.2135 - root_mean_squared_error: 2.4927\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 5.4302 - root_mean_squared_error: 2.3303\n",
            "Epoch 13/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 4.6130 - root_mean_squared_error: 2.1478\n",
            "Epoch 14/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 3.8806 - root_mean_squared_error: 1.9699\n",
            "Epoch 15/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 3.2605 - root_mean_squared_error: 1.8057\n",
            "Epoch 16/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 2.7403 - root_mean_squared_error: 1.6554\n",
            "Epoch 17/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 2.3013 - root_mean_squared_error: 1.5170\n",
            "Epoch 18/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 1.9282 - root_mean_squared_error: 1.3886\n",
            "Epoch 19/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 1.6122 - root_mean_squared_error: 1.2697\n",
            "Epoch 20/50\n",
            "34/34 [==============================] - 45s 1s/step - loss: 1.3458 - root_mean_squared_error: 1.1601\n",
            "Epoch 21/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 1.1214 - root_mean_squared_error: 1.0590\n",
            "Epoch 22/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.9349 - root_mean_squared_error: 0.9669\n",
            "Epoch 23/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.7811 - root_mean_squared_error: 0.8838\n",
            "Epoch 24/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.6551 - root_mean_squared_error: 0.8094\n",
            "Epoch 25/50\n",
            "34/34 [==============================] - 45s 1s/step - loss: 0.5535 - root_mean_squared_error: 0.7440\n",
            "Epoch 26/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.4722 - root_mean_squared_error: 0.6872\n",
            "Epoch 27/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.4076 - root_mean_squared_error: 0.6384\n",
            "Epoch 28/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.3567 - root_mean_squared_error: 0.5972\n",
            "Epoch 29/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.3168 - root_mean_squared_error: 0.5629\n",
            "Epoch 30/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2859 - root_mean_squared_error: 0.5347\n",
            "Epoch 31/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2621 - root_mean_squared_error: 0.5119\n",
            "Epoch 32/50\n",
            "34/34 [==============================] - 45s 1s/step - loss: 0.2439 - root_mean_squared_error: 0.4939\n",
            "Epoch 33/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2301 - root_mean_squared_error: 0.4797\n",
            "Epoch 34/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2196 - root_mean_squared_error: 0.4686\n",
            "Epoch 35/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2118 - root_mean_squared_error: 0.4602\n",
            "Epoch 36/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2058 - root_mean_squared_error: 0.4536\n",
            "Epoch 37/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.2013 - root_mean_squared_error: 0.4486\n",
            "Epoch 38/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1979 - root_mean_squared_error: 0.4449\n",
            "Epoch 39/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1954 - root_mean_squared_error: 0.4421\n",
            "Epoch 40/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1936 - root_mean_squared_error: 0.4400\n",
            "Epoch 41/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1922 - root_mean_squared_error: 0.4384\n",
            "Epoch 42/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1911 - root_mean_squared_error: 0.4371\n",
            "Epoch 43/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1903 - root_mean_squared_error: 0.4363\n",
            "Epoch 44/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1898 - root_mean_squared_error: 0.4357\n",
            "Epoch 45/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1894 - root_mean_squared_error: 0.4352\n",
            "Epoch 46/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1890 - root_mean_squared_error: 0.4348\n",
            "Epoch 47/50\n",
            "34/34 [==============================] - 45s 1s/step - loss: 0.1888 - root_mean_squared_error: 0.4345\n",
            "Epoch 48/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1886 - root_mean_squared_error: 0.4343\n",
            "Epoch 49/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1885 - root_mean_squared_error: 0.4342\n",
            "Epoch 50/50\n",
            "34/34 [==============================] - 44s 1s/step - loss: 0.1884 - root_mean_squared_error: 0.4341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjyXD9-Y9A33",
        "outputId": "43fd59d3-669d-4a58-affc-cf2490c63374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss_T, RMSE_T = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train Error: %f' % (RMSE_T))\n",
        " \n",
        "# evaluate model on test dataset dataset\n",
        "loss_V, RMSE_V = model.evaluate(x_test,y_test, verbose=0)\n",
        "print('Test Error: %f' % (RMSE_V))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Error: 0.434008\n",
            "Test Error: 0.417338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daLyVCcEzjmJ",
        "outputId": "5dce7ff0-0b10-4f13-bf68-8f765ed2f1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "fig, ax1 = plt.subplots()\n",
        "epochs_arr =[i for i in range(0,epochs)]\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('RMSE', color=color)\n",
        "ax1.plot(epochs_arr, history.history['root_mean_squared_error'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "plt.show()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'root_mean_squared_error'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}